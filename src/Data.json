{
    "Project": {
        "conduct": {
            "title": "Conduct",
            "dateStart": "June 2019",
            "dataEnd": "August 2019",
            "blurb": "This project allows me to control audio playback on my computer by making gestures with my hands. It uses a YOLOv3 algorithm on webcam input.",
            "img": "0.jpg",
            "tags": [
                "TensorFlow 2.0",
                "Computer Vision",
                "YOLOv3",
                "OpenLabeling",
                "OpenCV"
            ],
            "gallery": [
                {
                    "src": "0.jpg",
                    "width": "320",
                    "height": "320"
                },
                {
                    "src": "1.jpg",
                    "width": "1347",
                    "height": "973"
                },
                {
                    "src": "2.jpg",
                    "width": "1514",
                    "height": "497"
                }
            ],
            "video": "https://www.youtube.com/embed/CPZNZpvM5Xc",
            "url": "/project/conduct",
            "intro": "I’m always listening to music while I work, and I thought it would be cool to control my music through very intuitive hand gestures. This is one case where voice recognition gets unreliable; if you’re blasting music, the microphone has trouble picking up your commands. So, you use your hands to control the computer, like a conductor directs a symphony.",
            "learned": [
                "YOLOv3",
                "Tuning hyperparameters",
                "Learning rate decay and warmup epochs to help a network converge",
                "Processing and displaying outputs using OpenCV"
            ],
            "custom": [
                {
                    "header": "What's Next?",
                    "body": "There are a lot of things that could be added to this project fairly easily. I could mess around with the hyperparameters a little bit more to improve accuracy, I could photograph and tag more data, and I could add more gestures, like one for skip track. Top priority would be to increase the size of the dataset. I created and tagged the dataset myself, in one afternoon, in the same room, in the same clothes. Needless to say, the system isn’t really robust, since it’s only trained on 1500 similar frames. Sigh… tagging computer vision data is such a bore, but that’s the only surefire way to improve my model."
                }
            ],
            "howItWorks": "The system is pretty easy to understand on a high level. There’s an infinite loop, taking images from the webcam that’s attached to my wall, and feeding them to a neural network. The YOLOv3 network is nice and fast, with enough accuracy to pick up my hands and classify them. The network not only detects where the hands are, but classifies them as one of 6 hand states: palm, back, flat, vertical, fist, and neutral. After the network has given its predictions, it’s just a matter of simple logic to perform the audio modifications through terminal commands."
        },
        "ajax": {
            "title": "AJAX ASR",
            "dateStart": "Sept 2018",
            "dataEnd": "Feb 2019",
            "blurb": "Voice Recognition system built with Google Tensorflow.",
            "img": "0.jpg",
            "tags": [
                "TensorFlow",
                "NLP",
                "NumPy",
                "Tensorboard",
                "Keras",
                "LSTM"
            ],
            "gallery": [
                {
                    "src": "0.jpg",
                    "width": "320",
                    "height": "320"
                },
                {
                    "src": "1.jpg",
                    "width": "1527",
                    "height": "472"
                },
                {
                    "src": "2.jpg",
                    "width": "3264",
                    "height": "4352"
                },
                {
                    "src": "3.jpg",
                    "width": "361",
                    "height": "286"
                }
            ],
            "video": null,
            "url": "/project/ajax",
            "intro": "This is my longest TensorFlow project, which all started with a frustration with a horrible voice recognition library. I decided to give it a shot myself, using Google TensorFlow Maching Learning. Currently, I have some parts working with a sub-optimal accuracy, and I'm looking into different models and methods to achieve great voice recognition. You can find all my code on my GitHub, right here.",
            "learned": [
                "Implementing and testing sequence classification neural networks",
                "Google Tensorflow, NumPy, Pyaudio, and many other small libraries",
                "Patience",
                "A Research, Build, Test cycle to complete a project"
            ],
            "custom": [],

            "howItWorks": "Currently, I've only trained a word classifier working, capable at differentiating 18 different words apart, with about 92% accuracy. The idea was to determine where the word breaks were, partition the sound file into words, and then classify from there. However, with a low classification accuracy, I'm currently looking into a new approach, using a sequence to sequence LSTM network to turn the sound byte into phenomes first. The good news is that I already have the data; I wrote a python script that automatically labels and records my voice, making data collection easy."
        },
        "tripwire": {
            "title": "Tripwire",
            "dateStart": "June 2019",
            "dataEnd": "June 2019",
            "blurb": "An app built in React Native that triggers alarms when in proximity to GPS coordinates.",
            "img": "0.jpg",
            "tags": [
                "React Native",
                "EngHack 2019",
                "UI/UX"
            ],
            "video": null,
            "url": "/project/tripwire",
            "intro": "This was a project I created with three of my friends for EngHack 2019. We decided to tackle a light problem: we were all missing our public transit stops because we were reading, sleeping, or on our phones. Obviously, we needed a way to alert us when we got close to a bus stop or specific location. We were all new to React Native, so it was pretty rough, but we all had a good time.",
            "learned": [
                "React Native, specifically navigation in React Native",
                "Advanced Git VC to get four devs working together on one project",
                "Rapid Prototyping in a team"
            ],
            "gallery": [
                {
                    "src": "1.jpg",
                    "width": "1080",
                    "height": "2340"
                },
                {
                    "src": "3.jpg",
                    "width": "1080",
                    "height": "2340"
                },
                {
                    "src": "2.jpg",
                    "width": "1080",
                    "height": "2340"
                },
                {
                    "src": "0.jpg",
                    "width": "320",
                    "height": "320"
                },
                {
                    "src": "4.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "5.jpg",
                    "width": "4608",
                    "height": "3456"
                }
            ],
            "custom": [],

            "howItWorks": "The app uses the GPS in the phone for its main functionality. The user can set certain coordinates as waypoints, and specify what kind of alarm should trigger when the phone came within a specified radius of the point."
        },
        "website": {
            "title": "This Website",
            "date-start": "Dec 2018",
            "date-end": "Present",
            "blurb": "This website is built by myself from scratch, designed in Illustrator, and coded using React.",
            "img": "0.jpg",
            "tags": [
                "React",
                "Frontend",
                "Design",
                "Illustrator"
            ],
            "gallery": [
                {
                    "src": "0.jpg",
                    "width": "5",
                    "height": "5"
                },
                {
                    "src": "1.jpg",
                    "width": "6215",
                    "height": "5432"
                }
            ],
            "intro": "I designed and coded this website entirely by myself in 2018, but it was in pure HTML and CSS. I used Illustrator to lay everything out and get a feel for the design. The project got way to large to maintain, and editing the HTML files for each individual page was a pain. So, I purchased a book on the React Framework, and spun this current website over a few weekends, learning as I went.",
            "video": null,
            "url": "/project/website",
            "learned": [
                "React",
                "Creating dynamic websites, in which things move, slide, and interact",
                "Project Structuring for large websites"
            ],
            "custom": [],

            "howItWorks": "This website is built with create-react-app, and is highly abstracted. All the data is in one file, and all the styling and structure is in React Components. All the pages are procedurally generated, so if I want to add a project, I just have to put the information into the data file. I used libraries for the image gallery and the Parallax banners, but everything else I coded myself. While a lot of people have told me that I shouldn't re-invent the wheel, I find value in learning how to build these things by myself."
        },
        "speaker": {
            "title": "DIY Speaker",
            "date-start": "June 2018",
            "date-end": "July 2018",
            "blurb": "I built a speaker and amplifier circuit from scratch using components found at a hardware store, soldering it all together and testing it with an oscilliscope",
            "img": "0.jpg",
            "tags": [
                "Hardware",
                "Soldering",
                "3D Modelling",
                "3D Printing",
                "Oscilliscope"
            ],
            "gallery": [
                {
                    "src": "0.jpg",
                    "width": "5",
                    "height": "5"
                },
                {
                    "src": "1.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "2.jpg",
                    "width": "1286",
                    "height": "747"
                },
                {
                    "src": "3.jpg",
                    "width": "3300",
                    "height": "2444"
                },
                {
                    "src": "4.jpg",
                    "width": "3264",
                    "height": "3264"
                },
                {
                    "src": "5.jpg",
                    "width": "1013",
                    "height": "824"
                },
                {
                    "src": "6.jpg",
                    "width": "3264",
                    "height": "4352"
                }
            ],
            "intro": "During my Grade 12 Year, I had the wonderful opportunity to work with an ex-Hydro One electrical engineer, James Whatley, in my Computer Engineering 12 Class. We learned and then built voltage regulation circuits, amperage regulations circuits, full-wave rectifiers, but we were short on time at the end of the year. Eager to learn more, I talked a bit with my instructor and we agreed to meet for a few days in the early summer to work on another project: the portable speaker.",
            "url": "/project/speaker",
            "video": "https://www.youtube.com/embed/BCQs8cIpOGc",
            "learned": [
                "Operational Amplifier circuits",
                "Using an oscilliscope to debug physical circuits",
                "Audio signal processing, filtering, and amplifying",
                "Current and Voltage limiting circuits",
                "Soldering complex circuits from schematics"

            ],
            "custom": [],

            "howItWorks": "Currently, I've only trained a word classifier working, capable at differentiating 18 different words apart, with about 92% accuracy. The idea was to determine where the word breaks were, partition the sound file into words, and then classify from there. However, with a low classification accuracy, I'm currently looking into a new approach, using a sequence to sequence LSTM network to turn the sound byte into phenomes first. The good news is that I already have the data; I wrote a python script that automatically labels and records my voice, making data collection easy."
        },

        "custompc": {
            "title": "Custom PC",
            "dateStart": "June 2016",
            "dataEnd": "Jan 2018",
            "blurb": "I built and now maintain my own PC. You could say I'm a PC enthusiast.",
            "img": "4.jpg",
            "tags": [
                "Hardware",
                "Dual-Booting"
            ],
            "video": null,
            "url": "/project/custompc",
            "intro": "Over the last few years, I have slowly built and upgraded my personal computer. The project started in grade 10 when I dissected a few old computers from my father’s workplace. From there, I slowly purchased and salvaged parts for the the next two years, arriving at this system. Along the way, I learned a great deal about how PCs work, and how to repair them. I have also helped a few friends out with building their own systems. My current build dual-boots Windows and Ubuntu.",
            "learned": [
                "How all components of a computer are installed, and how they all work together",
                "How to design a cost-effective build that has all the features I need",
                "Configuring BIOS settings, and dual booting",
                "File system permissions and formatting"
            ],
            "gallery": [
                {
                    "src": "1.jpg",
                    "width": "3377",
                    "height": "4099"
                },
                {
                    "src": "3.jpg",
                    "width": "540",
                    "height": "960"
                },
                {
                    "src": "2.jpg",
                    "width": "3455",
                    "height": "4245"
                },
                {
                    "src": "0.jpg",
                    "width": "3456",
                    "height": "4063"
                }
            ],
            "custom": [],
            "howItWorks": "I don't like being slowed down by hardware, so my rig is pretty beefy. It has a GTX 1070 graphics card, which is capable of training large neural networks. I have an intel 8600K CPU, which is a 6 core processor; it's great for multitasking. Couple that with a fast solid state drive, and I've got a pretty fast system."
        },
        "addingsoftware": {
            "title": "ScoutTech Software",
            "dateStart": "April 2017",
            "dataEnd": "June 2017",
            "blurb": "Software created for ScoutTech Outfitters to automate the adding of products to various databases.",
            "img": "0.jpg",
            "tags": [
                "Java",
                "Automation"
            ],
            "video": null,
            "url": "/project/addingsoftware",
            "intro": "In the spring of 2017, I was getting pretty good at Java in preparation for the AP exam, and I was looking to apply what I had been studying. At the same time, I was given the boring task of adding products to our database at ScoutTech. The database was slow, mistakes were frequent, a ton of steps were repeated, and it was mind-numbing. So, after doing a bunch of research on the project, I convinced my boss to pay me to develop a desktop that could add products quickly. Over a year later, that same system is being used to add products over twice as fast as the traditional method.",
            "learned": [
                "Agile Development, working closely with the client",
                "Writing and reading large amounts of data in CSV files in Java",
                "Object Oriented Programming experience in the real world",
                "Java Swing UI"
            ],
            "gallery": [
                {
                    "src": "1.jpg",
                    "width": "699",
                    "height": "710"
                },
                {
                    "src": "2.jpg",
                    "width": "540",
                    "height": "960"
                },
                {
                    "src": "3.jpg",
                    "width": "1413",
                    "height": "868"
                }
            ],
            "custom": [],

            "howItWorks": "The design is pretty simple. ChannelAdvisor, the database, accepts two forms of products: Standards and Bundles. Standards are for stand-alone products, like tents, stoves, shovels, etc. Bundles are for very similar products, like apparel that is the same except for size and colour. In each bundle, there is a parent and multiple children. The child products inherit most of their information from the parent. After the user of the Java Program chooses Bundle or Standard, They are greeted with the information page. There are around 12 fields that need to be filled out to make a valid product. When they are filled out, the program stores every product as an object in the system memory. The user can continue to create products and they will be saved in the same way. Once the user clicks “export” on the main page, the program takes all the products in its memory and writes them to a CSV file according to the Channeladvisor formatting rules. The resulting CSV file can then be uploaded directly into ChannelAdvisor."
        }
    },
    "Experience": {
        "watonomous": {
            "title": "Watonomous Design Team",
            "dateStart": "April 2019",
            "dataEnd": "Present",
            "blurb": "Watonomous is the Self-Driving Car team at the University of Waterloo. We compete in the SAE autodrive challenge, striving to create an autonomous vehicle.",
            "img": "0.jpg",
            "tags": [
                "Computer Vision",
                "TensorFlow",
                "OpenCV",
                "YOLO",
                "Keras"
            ],
            "url": "/experience/watonomous",
            "intro": "I am currently on the Perception team, which is the team's front line. We take in the data from cameras, LIDAR, and radar and attempt to process that data to pull out meaningful features.",
            "learned": [
                "OpenCV masking, searching",
                "Training YOLOv3 on a traffic light dataset",
                "Collaboration and Version Control on a huge, highly integrated codebase",
                "ROS",
                "OpenVino",
                "Managing a small group of developers to complete a larger goal",
                "Code Reviewing",
                "Two-week build, test, deploy cycles with a large team and system"
            ],
            "gallery": [
                {
                    "src": "1.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "3.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "2.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "4.jpg",
                    "width": "3456",
                    "height": "4608"
                }
            ],
            "video": null,
            "description": "I've worked on a few systems within perception. I experimented in railroad bar detection, and I've trained a YOLOv3 model on Traffic Light detection.",
            "custom": [
                {
                    "header": "Technical Lead",
                    "body": "My current position in the team is that of a Technical Lead on the Perception Sub-team. I'm assigned a project, such as cyclist detection, road line detection, etc. I then lead a small group of core members to accomplish said task. This usually involves processing data, training a neural network, and evaluating it. I'm also responsible for keeping up to date on research in the machine vision space, and understanding how the whole watonomous codebase works. This means that I do a lot of code reviews, pull requests, and debugging."
                }
            ]
        },
        "truenorth": {
            "title": "True North 2019",
            "dateStart": "June 2019",
            "dataEnd": "June 2019",
            "blurb": "Technology for good conference in Kitchener, Ontario.",
            "img": "0.jpg",
            "tags": [
                "Ethics in Tech"
            ],
            "url": "/experience/truenorth",
            "intro": "I attended The True North Tech Conference with my friends from the Wawanesa Insurance innovation outpost. The conference was hosted by Communitech, in Kitchener. There conference focused around tech for good. Privacy, security, implications of new technology. ",
            "learned": [
                "Ethics in technology",
                "Providing digital solutions to social issues"
            ],
            "video": null,
            "gallery": [
                {
                    "src": "1.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "3.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "2.jpg",
                    "width": "3456",
                    "height": "4608"
                }
            ]
        },
        "wawanesa": {
            "title": "Wawanesa Insurance Developer",
            "date-start": "April 2019",
            "date-end": "August 2019",
            "blurb": "For my first co-op term, I was working in Communitech for the Wawanesa Insurance Innovation Lab.",
            "intro": "I couldn't have asked for a better first coop. My job was to build proof-of-concept projects for Wawanesa Insurance, exploring potential applications of new technologies to the insurance industry. I completed three major projects, and was exposed to so many different frameworks and technologies. I learned so much, and learned while building.",
            "img": "1.jpg",
            "tags": [
                "AWS",
                "React",
                "Node.js",
                "React Native",
                "Frontend",
                "NLP",
                "BERT and Transformers",
                "Jupyter Notebooks"
            ],
            "learned": [
                "EC2, Sagemaker, Comprehend, Lambda, DynamoDB, API Gateway, ECR, Serverless",
                "React",
                "React Native",
                "Frontend",
                "NLP",
                "BERT and Transformers",
                "Jupyter Notebooks"
            ],
            "custom": [
                {
                    "header": "Twitter Sentiment Analysis",
                    "body": "My first proof of concept project was to create a system that helped a public relations team informed on the public’s opinions. Using Twitter’s API, I created a system that took tweets with a specific keyword and performed sentiment analysis on them. By storing the data in a database, the system is able to track Twitter user’s opinions on the keyword. The whole project was built in AWS with Serverless. I used AWS Lambda, DynamoDB, Comprehend, and API Gateway. My Node.js code tied all those systems together."
                },
                {
                    "header": "Instant Verification",
                    "body": "I built a similar system for Instagram, but for a different purpose. A big issue in the insurance industry is fraud. Thankfully, quite a few people incriminate themselves on social media, by posting things that prove their claim is false. I designed a system that looks at a user’s instagram profile for posts relating to the claim, whether it be travel, automotive, etc. This data is retrieved with a flask application, and then sent off to a React frontend to be reviewed."
                }
            ],
            "video": null,
            "gallery": [
                {
                    "src": "1.jpg",
                    "width": "1",
                    "height": "1"
                },
                {
                    "src": "3.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "2.jpg",
                    "width": "4608",
                    "height": "3456"
                },
                {
                    "src": "4.jpg",
                    "width": "2457",
                    "height": "4603"
                },
                {
                    "src": "5.jpg",
                    "width": "3456",
                    "height": "4608"
                },
                {
                    "src": "6.jpg",
                    "width": "3456",
                    "height": "4608"
                }
            ],
            "url": "/experience/wawanesa"
        },
        "camping": {
            "title": "Camping Trips",
            "dateStart": "Super Early",
            "dataEnd": "Present",
            "blurb": "One of my more intense hobbies is camping, specifically canoe tripping.",
            "img": "0.jpg",
            "tags": [
                "Planning",
                "Management",
                "Communication",
                "White Water Canoeing"
            ],
            "url": "/experience/camping",
            "intro": "Ever since I was little, I was going on camping trips with my family; my father is an outdoor enthusiast. My family goes on a canoe trip just about every summer, and recently we’ve been doing whitewater paddling down various rivers in Northern Ontario. Through the Scouts Canada program, I’ve also been exposed to lightweight backpacking trips and winter camping.",
            "learned": [
                "Quick Decision making and communication skills",
                "Logistics and planning",
                "Teamwork and perseverance"
            ],
            "gallery": [
                {
                    "src": "1.jpg",
                    "width": "5312",
                    "height": "2988"
                },
                {
                    "src": "3.jpg",
                    "width": "2736",
                    "height": "3648"
                },
                {
                    "src": "2.jpg",
                    "width": "2448",
                    "height": "2448"
                },
                {
                    "src": "4.jpg",
                    "width": "540",
                    "height": "960"
                }
            ],
            "custom": [
                {
                    "header": "Most Recent Trip",
                    "body": "My most recent trip was a 12-Day canoe trip down the Missinaibi River. We went from Dog Lake to Mattice, with a lot of rain and whitewater in between. Below is a video I made from the GoPro footage and pictures taken on the trip. I edited it all in Adobe Premiere Pro, and there's a longer version for those interested in all the whitewater."
                }
            ],
            "video": "https://www.youtube.com/embed/jbu0bRDEHXU"
        }
    }
}