{
    "Project": {
        "ajax": {
            "title": "AJAX Voice Recognition",
            "dateStart": "Sept 2018",
            "dataEnd": "Present",
            "blurb": "Voice Recognition system built with Google Tensorflow.",
            "img": "ajax.jpg",
            "tags": [
                "TensorFlow",
                "NLP",
                "NumPy",
                "Tensorboard",
                "Keras",
                "YAAAAAAAAA"
            ],
            "video": null,
            "url": "/project/ajax",
            "intro": "This is my longest ongoing project, which all started with a frustration with a horrible voice recognition library. I decided to give it a shot myself, using Google TensorFlow Maching Learning. Currently, I have some parts working with a sub-optimal accuracy, and I'm looking into different models and methods to achieve great voice recognition. You can find all my code on my GitHub, right here.",
            "learned": [
                "Implementing and testing sequence classification neural networks",
                "Google Tensorflow, NumPy, Pyaudio, and many other small libraries",
                "Patience",
                "A Research, Build, Test cycle to complete a project"
            ],
            "howItWorks": "Currently, I've only trained a word classifier working, capable at differentiating 18 different words apart, with about 92% accuracy. The idea was to determine where the word breaks were, partition the sound file into words, and then classify from there. However, with a low classification accuracy, I'm currently looking into a new approach, using a sequence to sequence LSTM network to turn the sound byte into phenomes first. The good news is that I already have the data; I wrote a python script that automatically labels and records my voice, making data collection easy."
        },
        "website": {
            "title": "This Website",
            "date-start": "Dec 2018",
            "date-end": "Present",
            "blurb": "This website is built by myself from scratch, designed in Illustrator, and coded using React.",
            "img": "website.jpg",
            "tags": [
                "React",
                "Frontend",
                "Design",
                "Illustrator"
            ],
            "intro": "It’s kinda weird to write about a website on the website itself… I designed and coded this website entirely by myself over the 2018-2019 winter break, and it serves as a digital portfolio for all my projects and experiences. I used Illustrator to lay everything out and get a feel for the design, and I coded everything into HTML and CSS using Adobe Dreamweaver. I’ll be updating this website from time to time obviously, if I feel the need to add something new. If you happen to spot an error or just have a suggestion, please please please contact me so that I can fix it right away!",
            "video": null,
            "url": "/project/website",
            "learned": "Implementing and testing sequence classification neural networks\nGoogle Tensorflow, NumPy, Pyaudio, and many other small libraries\nPatience\nA Research, Build, Test cycle to complete a project",
            "howItWorks": "Currently, I've only trained a word classifier working, capable at differentiating 18 different words apart, with about 92% accuracy. The idea was to determine where the word breaks were, partition the sound file into words, and then classify from there. However, with a low classification accuracy, I'm currently looking into a new approach, using a sequence to sequence LSTM network to turn the sound byte into phenomes first. The good news is that I already have the data; I wrote a python script that automatically labels and records my voice, making data collection easy."
        },
        "speaker": {
            "title": "DIY Portable Speaker",
            "date-start": "June 2018",
            "date-end": "July 2018",
            "blurb": "I built a speaker and amplifier circuit from scratch using components found at a hardware store, soldering it all together and testing it with an oscilliscope",
            "img": "website.jpg",
            "tags": [
                "Hardware",
                "Soldering",
                "3D Modelling",
                "3D Printing",
                "Oscilliscope"
            ],
            "intro": "During my Grade 12 Year, I had the wonderful opportunity to work with an ex-Hydro One electrical engineer, James Whatley, in my Computer Engineering 12 Class. We learned and then built voltage regulation circuits, amperage regulations circuits, full-wave rectifiers, but we were short on time at the end of the year. Eager to learn more, I talked a bit with my instructor and we agreed to meet for a few days in the early summer to work on another project: the portable speaker.",
            "url": "/project/speaker",
            "video":"https://www.youtube.com/embed/BCQs8cIpOGc",
            "learned": "Implementing and testing sequence classification neural networks\nGoogle Tensorflow, NumPy, Pyaudio, and many other small libraries\nPatience\nA Research, Build, Test cycle to complete a project",
            "howItWorks": "Currently, I've only trained a word classifier working, capable at differentiating 18 different words apart, with about 92% accuracy. The idea was to determine where the word breaks were, partition the sound file into words, and then classify from there. However, with a low classification accuracy, I'm currently looking into a new approach, using a sequence to sequence LSTM network to turn the sound byte into phenomes first. The good news is that I already have the data; I wrote a python script that automatically labels and records my voice, making data collection easy."
        }
    },
    "Experience": {
        "watonomous": {
            "title": "Watonomous Design Team",
            "dateStart": "April 2019",
            "dataEnd": "Present",
            "blurb": "Watonomous is the Self-Driving Car team at the University of Waterloo. We compete in the SAE autodrive challenge, striving to create an autonomous vehicle.",
            "img": "wato.jpg",
            "tags": ["Computer Vision","TensorFlow", "NumPy", "YOLO", "Keras", "YAAAAAAAAA"],
            "url": "/experience/watonomous",
            "intro": "I am currently on the Perception team, which is the team's front line. We take in the data from cameras, LIDAR, and radar and attempt to process that data to pull out meaningful features.",
            "learned":[

            ],
            "description": "I've worked on a few systems within perception. I experimented in railroad bar detection, and I've trained a YOLOv3 model on Traffic Light detection."
        },
        "wawanesa": {
            "title": "Wawanesa Insurance Developer",
            "date-start": "April 2019",
            "date-end": "August 2019",
            "blurb": "This website is built by myself from scratch, designed in Illustrator, and coded using React.",
            "img": "logo.png",
            "tags": ["React", "Frontend", "Design", "Illustrator"],
            "url": "/project/website"
        }
    }
}